{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10 - Unsupervised Learning\n",
    "The topics of this chapter are\n",
    "\n",
    "- Principal Components Analysis\n",
    "- Clustering Methods\n",
    "\n",
    "## Principal Component Analysis\n",
    "Principal Component Analysis (PCA) is a technique for unsupervised exploratory data analysis. It is used to reduce the dimensions of the observations' space so that the main components, represented as linear combinations of the original predictors, can be represented in a space of lower dimensions. If p is the number of predictors, we can represent the first principal component of the $i$th observation as \n",
    "\n",
    "$$z_{i1} = \\phi_{11}x_{i1} + \\phi_{21}x_{i2} + ... + \\phi_{p1}x_{ip}$$\n",
    "\n",
    "subject to the constraint\n",
    "\n",
    "$$\\sum_{j=1}^p \\phi_{j1}^2 = 1$$\n",
    "\n",
    "The coefficients $\\phi_{j1}$ are called loadings. We assume that all variables $x_j$ are standardized so that they have standard deviation one and mean value zero \n",
    "\n",
    "$$\\bar{x}_j = \\frac{1}{n} \\sum_{i=1}^n x_{ij} = 0$$\n",
    "\n",
    "We want the first principal component $z_{1}$ to have the largest variance\n",
    "\n",
    "$$Var(z_1) = \\frac{1}{n} \\sum_{i=1}^n (z_{i1} - \\bar{z}_1)^2$$\n",
    "\n",
    "This means that we have to maximize $Var(z_1)$. We can simplify the expression of the variance as follows\n",
    "\n",
    "$$\\bar{z}_1 = \\frac{1}{n} \\sum_{i=1}^n z_{i1} = \\frac{1}{n} \\sum_{i=1}^n \\sum_{j=1}^p \\phi_{j1} x_{ij} = \\sum_{j=1}^p \\phi_{j1} (\\frac{1}{n} \\sum_{i=1}^n x_{ij}) = \\sum_{j=1}^p \\phi_{j1} \\bar{x}_j = 0$$\n",
    "\n",
    "so that \n",
    "\n",
    "$$Var(z_1) = \\frac{1}{n} \\sum_{i=1}^n z_{i1}^2 = \\frac{1}{n} \\sum_{i=1}^n (\\sum_{j=1}^p \\phi_{j1} x_{ij})^2$$\n",
    "\n",
    "and the problem to find the coefficients $\\phi_{j1}$ that maximize the variance $Var(z_1)$ becomes\n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\phi_{k1}} Var(z_1) = \\frac{2}{n} \\sum_{i=1}^n (\\sum_{j=1}^p \\phi_{j1} x_{ij}) x_{ik} = 0$$\n",
    "\n",
    "that is a system of p linear equations in $\\phi_{j1}$ that can be solved with the [singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition) technique.  \n",
    "\n",
    "After we have found the first principal component, we can determine the second principal component as the direction that is orthogonal to the first principal component and that has the highest variance in this subspace, practically repeating the same procedure we have followed to compute the first principal component. A geometric interpretation of the first principal component is that it is the line that is the closest to the n observations. The first two principal components determine the plane that is the closest to the observations, and so forth. We can determine the first M < p principal components that represent the bulk of the variability of our observations. The proportion of variance captured by the $m$th principal component is represented by the ratio \n",
    "\n",
    "$$\\frac{Var(z_m)}{ \\sum_{j=1}^p Var(x_j)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Methods\n",
    "There are two types of clustering methods: K-Means clustering and Hierarchical clustering. In K-Means clustering the number of clusters K must be specified in advance.\n",
    "We want the distances between observations within each cluster \n",
    "\n",
    "$$W(C_k) = \\frac{1}{|C_k|} \\sum_{i,i' \\in C_k} \\sum_{j=1}^p (x_{ij} - x_{i'j})^2$$\n",
    "\n",
    "such that\n",
    "\n",
    "$$\\sum_{k=1}^K W(C_k)$$\n",
    "\n",
    "is minimized. Each observation belongs to only one of the non-overlapping clusters.\n",
    "\n",
    "In hierarchical clustering the number of classes is not specified in advance. The process starts by assigning to each observation its own cluster and then by fusing pairs of closest clusters. The process is repeated till all clusters are fused into a single one. The process can be represented as a dendrogram, a tree-like structure that is built bottom-up from the observations to the root that represents the fusion of all the observations in one single cluster. Different methods of computing the dissimilarity measures between clusters can be implemented and different metrics, such as euclidean metrics and correlation, can be used. It depends on the problem at hand to choose which level of the dendrogram, and as a consequence the number of clusters, is most effective in representing the structure of the observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Principal Component Analysis\n",
    "We wil perform PCA on the USArrests data set. The data set contains the number of four types of crimes in each state of the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Murder'</li>\n",
       "\t<li>'Assault'</li>\n",
       "\t<li>'UrbanPop'</li>\n",
       "\t<li>'Rape'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Murder'\n",
       "\\item 'Assault'\n",
       "\\item 'UrbanPop'\n",
       "\\item 'Rape'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Murder'\n",
       "2. 'Assault'\n",
       "3. 'UrbanPop'\n",
       "4. 'Rape'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Murder\"   \"Assault\"  \"UrbanPop\" \"Rape\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>50</li>\n",
       "\t<li>4</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 50\n",
       "\\item 4\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 50\n",
       "2. 4\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 50  4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(USArrests); dim(USArrests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Murder</dt>\n",
       "\t\t<dd>7.788</dd>\n",
       "\t<dt>Assault</dt>\n",
       "\t\t<dd>170.76</dd>\n",
       "\t<dt>UrbanPop</dt>\n",
       "\t\t<dd>65.54</dd>\n",
       "\t<dt>Rape</dt>\n",
       "\t\t<dd>21.232</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Murder] 7.788\n",
       "\\item[Assault] 170.76\n",
       "\\item[UrbanPop] 65.54\n",
       "\\item[Rape] 21.232\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Murder\n",
       ":   7.788Assault\n",
       ":   170.76UrbanPop\n",
       ":   65.54Rape\n",
       ":   21.232\n",
       "\n"
      ],
      "text/plain": [
       "  Murder  Assault UrbanPop     Rape \n",
       "   7.788  170.760   65.540   21.232 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply(USArrests, 2, mean) # applies the mean() function to the columns (margin 2, 1 for rows) of the USArrests data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Murder</dt>\n",
       "\t\t<dd>18.9704653061224</dd>\n",
       "\t<dt>Assault</dt>\n",
       "\t\t<dd>6945.16571428571</dd>\n",
       "\t<dt>UrbanPop</dt>\n",
       "\t\t<dd>209.518775510204</dd>\n",
       "\t<dt>Rape</dt>\n",
       "\t\t<dd>87.7291591836735</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Murder] 18.9704653061224\n",
       "\\item[Assault] 6945.16571428571\n",
       "\\item[UrbanPop] 209.518775510204\n",
       "\\item[Rape] 87.7291591836735\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Murder\n",
       ":   18.9704653061224Assault\n",
       ":   6945.16571428571UrbanPop\n",
       ":   209.518775510204Rape\n",
       ":   87.7291591836735\n",
       "\n"
      ],
      "text/plain": [
       "    Murder    Assault   UrbanPop       Rape \n",
       "  18.97047 6945.16571  209.51878   87.72916 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply(USArrests, 2, var) # applies the var() function to compute the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a huge difference in the values because of the different units used. We use the prcomp() to perform PCA and we set the scale argument to true to standardize the variables' standard deviation to remove the effect due to the different units of measure used for each of them. We can see the proportion of the variance captured by each principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Importance of components:\n",
       "                          PC1    PC2     PC3     PC4\n",
       "Standard deviation     1.5749 0.9949 0.59713 0.41645\n",
       "Proportion of Variance 0.6201 0.2474 0.08914 0.04336\n",
       "Cumulative Proportion  0.6201 0.8675 0.95664 1.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.out <- prcomp(USArrests, scale = TRUE)\n",
    "summary(pr.out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the loadings of each principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>PC1</th><th scope=col>PC2</th><th scope=col>PC3</th><th scope=col>PC4</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Murder</th><td>-0.5358995 </td><td> 0.4181809 </td><td>-0.3412327 </td><td> 0.64922780</td></tr>\n",
       "\t<tr><th scope=row>Assault</th><td>-0.5831836 </td><td> 0.1879856 </td><td>-0.2681484 </td><td>-0.74340748</td></tr>\n",
       "\t<tr><th scope=row>UrbanPop</th><td>-0.2781909 </td><td>-0.8728062 </td><td>-0.3780158 </td><td> 0.13387773</td></tr>\n",
       "\t<tr><th scope=row>Rape</th><td>-0.5434321 </td><td>-0.1673186 </td><td> 0.8177779 </td><td> 0.08902432</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & PC1 & PC2 & PC3 & PC4\\\\\n",
       "\\hline\n",
       "\tMurder & -0.5358995  &  0.4181809  & -0.3412327  &  0.64922780\\\\\n",
       "\tAssault & -0.5831836  &  0.1879856  & -0.2681484  & -0.74340748\\\\\n",
       "\tUrbanPop & -0.2781909  & -0.8728062  & -0.3780158  &  0.13387773\\\\\n",
       "\tRape & -0.5434321  & -0.1673186  &  0.8177779  &  0.08902432\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | PC1 | PC2 | PC3 | PC4 |\n",
       "|---|---|---|---|---|\n",
       "| Murder | -0.5358995  |  0.4181809  | -0.3412327  |  0.64922780 |\n",
       "| Assault | -0.5831836  |  0.1879856  | -0.2681484  | -0.74340748 |\n",
       "| UrbanPop | -0.2781909  | -0.8728062  | -0.3780158  |  0.13387773 |\n",
       "| Rape | -0.5434321  | -0.1673186  |  0.8177779  |  0.08902432 |\n",
       "\n"
      ],
      "text/plain": [
       "         PC1        PC2        PC3        PC4        \n",
       "Murder   -0.5358995  0.4181809 -0.3412327  0.64922780\n",
       "Assault  -0.5831836  0.1879856 -0.2681484 -0.74340748\n",
       "UrbanPop -0.2781909 -0.8728062 -0.3780158  0.13387773\n",
       "Rape     -0.5434321 -0.1673186  0.8177779  0.08902432"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.out$rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three crimes reported equally contribute to the first principal component that can be interpreted as a predictor for crimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.out$rotation <- - pr.out$rotation\n",
    "pr.out$x <- - pr.out$x\n",
    "biplot(pr.out, scale = 0, cex = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now work out an exercise. We have a data set of 300 observations with 200 predictors with labes y. We have also a test set of 1000 labelled observations. We want to see whether we can use less predictors while keeping the bulk of the variance in the data. We start by loading the data, concatenating all the observations, and computing the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"data/10.R.RData\") # we load the 300x200 'x' matrix with its labels 'y' and the 1000x200 'x.test' matrix with its labels 'y.test'\n",
    "x.bind <- rbind(x, x.test)\n",
    "pr.out <- prcomp(x.bind, scale = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principal components object, pr.out, contains the standard deviations of all the 200 principal components. We want to compute the proportion of the variance of the first five principal components to see whether they capture the bulk of it. We first compute the variance, then we compute the total variance and finally we compute the proportion of the variance of the first 5 principal components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.349856465332264"
      ],
      "text/latex": [
       "0.349856465332264"
      ],
      "text/markdown": [
       "0.349856465332264"
      ],
      "text/plain": [
       "[1] 0.3498565"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "variance <- (pr.out$sdev)^2\n",
    "total_variance <- sum(variance)\n",
    "prop_variance_5 <- sum(variance[1:5]) / total_variance\n",
    "prop_variance_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We see that 35 % of the variance is captured by the first 5 principal components. Now we want to see what could be the mean squared error on the test set if we fit a linear into the 5-dimensional space of the first five principal components. We have to map the train observation x into z using the first 5 loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>5</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phi_5 <- t(pr.out$rotation[, 1:5])\n",
    "x_transpose <- t(x)\n",
    "z <- t(phi_5 %*% x_transpose)\n",
    "x.test_transpose <- t(x.test)\n",
    "z.test <- t(phi_5 %*% x.test_transpose)\n",
    "dat <- data.frame(\"y\" = y, \"z\" = z)\n",
    "dim(z.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit a linear model using the transformed training data and then we compute the predictions using the transformed test data such that we will be able to compute the mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = y ~ z, data = dat)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3.3004 -0.6899  0.0311  0.8082  2.5320 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.101474   0.061353   1.654 0.099205 .  \n",
       "zPC1         0.057576   0.008625   6.675 1.23e-10 ***\n",
       "zPC2        -0.018521   0.010013  -1.850 0.065352 .  \n",
       "zPC3        -0.031111   0.011903  -2.614 0.009417 ** \n",
       "zPC4        -0.051695   0.017941  -2.881 0.004252 ** \n",
       "zPC5        -0.134176   0.035585  -3.771 0.000197 ***\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 1.056 on 294 degrees of freedom\n",
       "Multiple R-squared:  0.1912,\tAdjusted R-squared:  0.1775 \n",
       "F-statistic:  13.9 on 5 and 294 DF,  p-value: 3.341e-12\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit <- lm(y ~ z, data = dat)\n",
    "summary(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.test_df <- data.frame(\"z\" = z.test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCI-60 Data Example\n",
    "[paper](https://www.pnas.org/content/pnas/100/14/8418.full.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
